{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# はじめに：このノートブックで学ぶこと\n",
    "\n",
    "このノートブックでは、RAG（Retrieval-Augmented Generation）の基本的な3つのステップ（チャンキング、検索、生成）の技術的な詳細を、一つ一つ実行しながら学びます。\n",
    "\n",
    "1.  **ステップA: チャンキング** - 大きなテキストを小さな塊（チャンク）に分割します。\n",
    "2.  **ステップB: 検索** - 質問と意味的に関連するチャンクを見つけ出します。\n",
    "3.  **ステップC: 生成** - 検索で見つけた情報を基に、AIが回答を生成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、このチュートリアルで必要となるPythonライブラリをインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (5.1.2)\n",
      "Requirement already satisfied: openai in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: python-dotenv in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (2.3.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from sentence-transformers) (2.9.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from sentence-transformers) (12.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from openai) (2.12.4)\n",
      "Requirement already satisfied: sniffio in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: filelock in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: requests in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: setuptools in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers openai python-dotenv numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、OpenAI APIを利用するためのAPIキーを設定します。\n",
    "このノートブックと同じ階層に`.env`という名前のファイルを作成し、その中に`OPENAI_API_KEY='あなたのAPIキー'`と記述してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI APIキーが設定されました。\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .envファイルを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai.api_key:\n",
    "    print('OpenAI APIキーが設定されました。')\n",
    "else:\n",
    "    print('エラー: .envファイルにOPENAI_API_KEYが見つかりません。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習用のサンプルテキストをインポートします。本ファイルではsample_text_Aのみを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用のサンプルテキストを外部ファイルからインポートします\n",
    "from sample_texts import sample_text_A, sample_text_B, DISPLAY_NAME_A, DISPLAY_NAME_B\n",
    "use_sample_text = sample_text_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ステップA：チャンキング（テキストの分割）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**なぜチャンキングが必要か？**\\n\n",
    "\\n\n",
    "大規模言語モデル（LLM）には、一度に処理できるテキストの長さ（コンテキストウィンドウ）に上限があります。そのため、長い文章をそのまま入力すると、情報が欠落したり、モデルがうまく処理できなかったりします。\\n\n",
    "\\n\n",
    "チャンキングは、元のテキストをモデルが扱いやすいサイズの小さな断片（チャンク）に分割するプロセスです。これにより、関連する情報だけを効率的に検索し、モデルに渡すことができるようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分割方法1：固定文字数\n",
    "\n",
    "最もシンプルな方法の一つが、テキストを指定した文字数で機械的に分割する方法です。文章の構造を考慮しないため、単語や文の途中で分割されてしまう可能性がありますが、実装は非常に簡単です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 固定文字数（100文字）での分割結果 ---\n",
      "チャンク 1: \n",
      "遥か未来、人類が宇宙へと進出した時代。\n",
      "ある小惑星帯に、老夫婦が静かに暮らしていました。\n",
      "夫はデブリ回収業者として宇宙を飛び回り、妻は小惑星の自宅で水耕栽培をしていました。\n",
      "ある日、妻がドッキングポ\n",
      "チャンク 2: ートで宇宙船の洗浄をしていると、\n",
      "観測史上ないほど巨大な宇宙葡萄の房が、ゆっくりと自転しながら近づいてきました。\n",
      "その葡萄は、一粒一粒が家ほどもあり、美しい紫色に輝いていました。\n",
      "「まあ、なんて珍しい\n",
      "チャンク 3: 葡萄でしょう」。\n",
      "妻は驚きながらも、マニピュレーターアームを巧みに操り、\n",
      "その巨大な葡萄の一粒を慎重に回収し、居住ブロックへと運び込みました。\n",
      "夕方、夫がデブリ回収の仕事を終えて帰還すると、妻はその巨\n",
      "チャンク 4: 大な葡萄を見せました。\n",
      "あまりの大きさと美しさに夫も目を見張りました。\n",
      "「これはきっと、伝説の『創世の葡萄』に違いない。食べれば不老不死になれるという…」。\n",
      "二人が期待に胸を膨らませ、レーザーカッター\n",
      "チャンク 5: でその葡萄の厚い皮に切れ込みを入れると、\n",
      "まばゆい光と共に、中から元気な男の子の赤ちゃんが現れたのです。\n",
      "宇宙葡萄から生まれたその子を、二人は「葡萄太郎（ぶどうたろう）」と名付けました。\n",
      "葡萄太郎は、\n",
      "チャンク 6: 老夫婦の愛情を一身に受け、\n",
      "小惑星の特殊な環境と栄養豊富な宇宙葡萄のエキスですくすくと育ちました。\n",
      "彼は生まれながらにして宇宙空間での活動に適応しており、驚異的な身体能力を持っていました。\n",
      "数年後、た\n",
      "チャンク 7: くましい青年に成長した葡萄太郎は、\n",
      "近隣の星系を荒らし回る悪名高い宇宙海賊「ジャークマター」の噂を耳にします。\n",
      "彼らは貴重な資源を略奪し、平和な植民星を破壊の危機に陥れていました。\n",
      "「僕が行って、ジャ\n",
      "チャンク 8: ークマターを懲らしめてきます」。\n",
      "葡萄太郎の決意は固く、妻は栄養満点の宇宙きび団子を、\n",
      "夫は最新型の小型宇宙艇を彼に与えました。\n",
      "旅の途中、葡萄太郎は3体のユニークな仲間と出会います。\n",
      "最初に訪れたサ\n",
      "チャンク 9: イバーパンクな機械惑星で、\n",
      "忠実なAIを搭載した犬型ロボット「イヌ-X」を仲間にしました。\n",
      "次に立ち寄ったジャングル惑星では、驚異的な知能を持つ猿型サイボーグ「サル-Z」の助けを借り、\n",
      "最後に、廃墟と\n",
      "チャンク 10: なった宇宙ステーションで、\n",
      "超高速で飛行する鳥型ドローン「キジ-V」を修理して仲間に加えました。\n",
      "葡萄太郎と3体の仲間たちは、宇宙艇でジャークマターの本拠地である暗黒星雲へと向かいました。\n",
      "そこは無数\n",
      "チャンク 11: のアステロイドが飛び交う危険な宙域でした。\n",
      "激しい弾幕をかいくぐり、敵の防衛網を突破した彼らは、\n",
      "ついに宇宙海賊の巨大な母船に乗り込みます。\n",
      "母船の内部は迷路のように入り組んでいましたが、\n",
      "イヌ-Xの\n",
      "チャンク 12: 解析能力、サル-Zのハッキング技術、キジ-Vの偵察能力を駆使して、\n",
      "葡萄太郎はついに首領の部屋へとたどり着きました。\n",
      "首領は巨大な体を持つ恐ろしい異星人でした。「我々の邪魔をするとは、愚かな地球人め！\n",
      "チャンク 13: 」。\n",
      "激しい戦闘の末、葡萄太郎は仲間たちとの連携プレイで首領を打ち破り、\n",
      "ジャークマターを降伏させました。彼は奪われた宝物と資源を解放し、\n",
      "それらを元の持ち主である各植民星に返還しました。\n",
      "葡萄太郎の\n",
      "チャンク 14: 活躍は全星系に知れ渡り、\n",
      "彼は宇宙の平和を守る英雄として、末永くその名を語り継がれることになりました。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chunk_by_size(text, chunk_size):\n",
    "    \"\"\"指定された文字数でテキストを分割する関数\"\"\"\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "chunk_size = 100\n",
    "chunks_fixed_size = chunk_by_size(use_sample_text, chunk_size)\n",
    "\n",
    "print(f\"--- 固定文字数（{chunk_size}文字）での分割結果 ---\")\n",
    "for i, chunk in enumerate(chunks_fixed_size):\n",
    "    print(f\"チャンク {i+1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分割方法2：改行（`\\n`）\n",
    "\n",
    "箇条書きや詩、コードのように、改行が意味的な区切りとなっているテキストに有効な方法です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 改行での分割結果 ---\n",
      "チャンク 1: 遥か未来、人類が宇宙へと進出した時代。\n",
      "チャンク 2: ある小惑星帯に、老夫婦が静かに暮らしていました。\n",
      "チャンク 3: 夫はデブリ回収業者として宇宙を飛び回り、妻は小惑星の自宅で水耕栽培をしていました。\n",
      "チャンク 4: ある日、妻がドッキングポートで宇宙船の洗浄をしていると、\n",
      "チャンク 5: 観測史上ないほど巨大な宇宙葡萄の房が、ゆっくりと自転しながら近づいてきました。\n",
      "チャンク 6: その葡萄は、一粒一粒が家ほどもあり、美しい紫色に輝いていました。\n",
      "チャンク 7: 「まあ、なんて珍しい葡萄でしょう」。\n",
      "チャンク 8: 妻は驚きながらも、マニピュレーターアームを巧みに操り、\n",
      "チャンク 9: その巨大な葡萄の一粒を慎重に回収し、居住ブロックへと運び込みました。\n",
      "チャンク 10: 夕方、夫がデブリ回収の仕事を終えて帰還すると、妻はその巨大な葡萄を見せました。\n",
      "チャンク 11: あまりの大きさと美しさに夫も目を見張りました。\n",
      "チャンク 12: 「これはきっと、伝説の『創世の葡萄』に違いない。食べれば不老不死になれるという…」。\n",
      "チャンク 13: 二人が期待に胸を膨らませ、レーザーカッターでその葡萄の厚い皮に切れ込みを入れると、\n",
      "チャンク 14: まばゆい光と共に、中から元気な男の子の赤ちゃんが現れたのです。\n",
      "チャンク 15: 宇宙葡萄から生まれたその子を、二人は「葡萄太郎（ぶどうたろう）」と名付けました。\n",
      "チャンク 16: 葡萄太郎は、老夫婦の愛情を一身に受け、\n",
      "チャンク 17: 小惑星の特殊な環境と栄養豊富な宇宙葡萄のエキスですくすくと育ちました。\n",
      "チャンク 18: 彼は生まれながらにして宇宙空間での活動に適応しており、驚異的な身体能力を持っていました。\n",
      "チャンク 19: 数年後、たくましい青年に成長した葡萄太郎は、\n",
      "チャンク 20: 近隣の星系を荒らし回る悪名高い宇宙海賊「ジャークマター」の噂を耳にします。\n",
      "チャンク 21: 彼らは貴重な資源を略奪し、平和な植民星を破壊の危機に陥れていました。\n",
      "チャンク 22: 「僕が行って、ジャークマターを懲らしめてきます」。\n",
      "チャンク 23: 葡萄太郎の決意は固く、妻は栄養満点の宇宙きび団子を、\n",
      "チャンク 24: 夫は最新型の小型宇宙艇を彼に与えました。\n",
      "チャンク 25: 旅の途中、葡萄太郎は3体のユニークな仲間と出会います。\n",
      "チャンク 26: 最初に訪れたサイバーパンクな機械惑星で、\n",
      "チャンク 27: 忠実なAIを搭載した犬型ロボット「イヌ-X」を仲間にしました。\n",
      "チャンク 28: 次に立ち寄ったジャングル惑星では、驚異的な知能を持つ猿型サイボーグ「サル-Z」の助けを借り、\n",
      "チャンク 29: 最後に、廃墟となった宇宙ステーションで、\n",
      "チャンク 30: 超高速で飛行する鳥型ドローン「キジ-V」を修理して仲間に加えました。\n",
      "チャンク 31: 葡萄太郎と3体の仲間たちは、宇宙艇でジャークマターの本拠地である暗黒星雲へと向かいました。\n",
      "チャンク 32: そこは無数のアステロイドが飛び交う危険な宙域でした。\n",
      "チャンク 33: 激しい弾幕をかいくぐり、敵の防衛網を突破した彼らは、\n",
      "チャンク 34: ついに宇宙海賊の巨大な母船に乗り込みます。\n",
      "チャンク 35: 母船の内部は迷路のように入り組んでいましたが、\n",
      "チャンク 36: イヌ-Xの解析能力、サル-Zのハッキング技術、キジ-Vの偵察能力を駆使して、\n",
      "チャンク 37: 葡萄太郎はついに首領の部屋へとたどり着きました。\n",
      "チャンク 38: 首領は巨大な体を持つ恐ろしい異星人でした。「我々の邪魔をするとは、愚かな地球人め！」。\n",
      "チャンク 39: 激しい戦闘の末、葡萄太郎は仲間たちとの連携プレイで首領を打ち破り、\n",
      "チャンク 40: ジャークマターを降伏させました。彼は奪われた宝物と資源を解放し、\n",
      "チャンク 41: それらを元の持ち主である各植民星に返還しました。\n",
      "チャンク 42: 葡萄太郎の活躍は全星系に知れ渡り、\n",
      "チャンク 43: 彼は宇宙の平和を守る英雄として、末永くその名を語り継がれることになりました。\n"
     ]
    }
   ],
   "source": [
    "# 空白行を除外するために、strip()で前後の空白を削除した上で、空でないものだけをリストに追加します\n",
    "chunks_newline = [line for line in use_sample_text.split('\\n') if line.strip()] \n",
    "\n",
    "print(\"--- 改行での分割結果 ---\")\n",
    "for i, chunk in enumerate(chunks_newline):\n",
    "    print(f\"チャンク {i+1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### まとめ\n",
    "\n",
    "このように、テキストの性質（自然な文章か、構造化されたリストかなど）によって、最適な分割方法は異なります。他にも、句読点（。や.）で区切る方法や、より高度な自然言語処理ライブラリ（`spaCy`や`NLTK`）を使って文単位で分割する方法などがあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ステップB：検索（Embedding & Retrieval）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embeddingとは何か？**\n",
    "\n",
    "Embedding（エンベディング）とは、テキスト（単語、文、文章）を、コンピュータが計算できる「ベクトル（数値のリスト）」に変換する技術です。このベクトルの重要な特徴は、**意味が近いテキスト同士は、ベクトル空間上で近い位置に配置される**という点です。\n",
    "\n",
    "例えば、「犬」と「猫」のベクトルは、「犬」と「机」のベクトルよりも近くなります。これにより、キーワードが完全に一致しなくても、意味的に関連する文章を見つけ出すことが可能になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shunsuke_arimura/Desktop/Tech0_desktop/社内Tech0/講義/w9~14_Webアプリ/宿題/RAG_App/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 事前学習済みのEmbeddingモデルをロードします。\n",
    "# 'all-MiniLM-L6-v2'は、高速かつ高品質で人気のあるモデルです。\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### チャンクと質問をベクトル化する\n",
    "\n",
    "それでは、先ほど作成したチャンクと、ユーザーからの質問を実際にベクトル化してみましょう。モデルの`encode()`メソッドを使います。\n",
    "※チャンク化は句読点で分割したものを使用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 質問のベクトル（最初の10次元） ---\n",
      "[-0.02801427  0.08815496  0.04257226  0.01339853 -0.04357269  0.10896344\n",
      "  0.04952611  0.04370211 -0.06755138 -0.05930566]\n",
      "ベクトルの形状: (1, 384)\n",
      "--- 最初のチャンクのベクトル（最初の10次元） ---\n",
      "[-0.02559412  0.04930006  0.04341166 -0.02697592 -0.02838277  0.055016\n",
      "  0.03523876  0.02062199 -0.01630171  0.02270142]\n",
      "ベクトルの形状: (31, 384)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ここでは、句読点で分割したチャンクを使用します\n",
    "chunks = [p + \"。\" for p in use_sample_text.split('。') if p.strip()]\n",
    "question = \"葡萄太郎の仲間とが倒した相手は誰ですか？\"\n",
    "\n",
    "# チャンクと質問をベクトル化\n",
    "chunk_embeddings = model.encode(chunks)\n",
    "question_embedding = model.encode([question])\n",
    "\n",
    "print(\"--- 質問のベクトル（最初の10次元） ---\")\n",
    "print(question_embedding[0, :10])\n",
    "print(\"ベクトルの形状:\", question_embedding.shape)\n",
    "\n",
    "print(\"--- 最初のチャンクのベクトル（最初の10次元） ---\")\n",
    "print(chunk_embeddings[0, :10])\n",
    "print(\"ベクトルの形状:\", chunk_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑このように、各テキストが高次元の数字のリスト（ベクトル）に変換されていることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### コサイン類似度で「意味の近さ」を計算する\n",
    "\n",
    "テキストをベクトル化できたら、次はその「近さ」を計算します。ベクトル空間における「近さ」を測る指標はいくつかありますが、最も一般的に使われるのが**コサイン類似度**です。\n",
    "\n",
    "コサイン類似度は、2つのベクトルが指す方向がどれだけ似ているかを示します。値は-1から1の範囲を取り、1に近いほど「似ている」と判断されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 各チャンクと質問の類似度スコア ---\n",
      "tensor([[0.5944, 0.6148, 0.5402, 0.5106, 0.5628, 0.5467, 0.5365, 0.6466, 0.5357,\n",
      "         0.4733, 0.5089, 0.4661, 0.6547, 0.6442, 0.5899, 0.5190, 0.6060, 0.5488,\n",
      "         0.6352, 0.7734, 0.6154, 0.5272, 0.7344, 0.5943, 0.5203, 0.6067, 0.6315,\n",
      "         0.5165, 0.7375, 0.5518, 0.5783]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "# 質問ベクトルと全チャンクベクトルのコサイン類似度を計算\n",
    "similarities = cos_sim(question_embedding, chunk_embeddings)\n",
    "\n",
    "print(\"--- 各チャンクと質問の類似度スコア ---\")\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 関連度の高い順に並べ替えたチャンク ---\n",
      "【順位 1 / スコア: 0.7734】\n",
      "旅の途中、葡萄太郎は3体のユニークな仲間と出会います。\n",
      "---\n",
      "【順位 2 / スコア: 0.7375】\n",
      "激しい戦闘の末、葡萄太郎は仲間たちとの連携プレイで首領を打ち破り、\n",
      "ジャークマターを降伏させました。\n",
      "---\n",
      "【順位 3 / スコア: 0.7344】\n",
      "葡萄太郎と3体の仲間たちは、宇宙艇でジャークマターの本拠地である暗黒星雲へと向かいました。\n",
      "---\n",
      "【順位 4 / スコア: 0.6547】\n",
      "宇宙葡萄から生まれたその子を、二人は「葡萄太郎（ぶどうたろう）」と名付けました。\n",
      "---\n",
      "【順位 5 / スコア: 0.6466】\n",
      "夕方、夫がデブリ回収の仕事を終えて帰還すると、妻はその巨大な葡萄を見せました。\n",
      "---\n",
      "【順位 6 / スコア: 0.6442】\n",
      "葡萄太郎は、老夫婦の愛情を一身に受け、\n",
      "小惑星の特殊な環境と栄養豊富な宇宙葡萄のエキスですくすくと育ちました。\n",
      "---\n",
      "【順位 7 / スコア: 0.6352】\n",
      "葡萄太郎の決意は固く、妻は栄養満点の宇宙きび団子を、\n",
      "夫は最新型の小型宇宙艇を彼に与えました。\n",
      "---\n",
      "【順位 8 / スコア: 0.6315】\n",
      "首領は巨大な体を持つ恐ろしい異星人でした。\n",
      "---\n",
      "【順位 9 / スコア: 0.6154】\n",
      "最初に訪れたサイバーパンクな機械惑星で、\n",
      "忠実なAIを搭載した犬型ロボット「イヌ-X」を仲間にしました。\n",
      "---\n",
      "【順位 10 / スコア: 0.6148】\n",
      "ある小惑星帯に、老夫婦が静かに暮らしていました。\n",
      "---\n",
      "【順位 11 / スコア: 0.6067】\n",
      "母船の内部は迷路のように入り組んでいましたが、\n",
      "イヌ-Xの解析能力、サル-Zのハッキング技術、キジ-Vの偵察能力を駆使して、\n",
      "葡萄太郎はついに首領の部屋へとたどり着きました。\n",
      "---\n",
      "【順位 12 / スコア: 0.6060】\n",
      "彼らは貴重な資源を略奪し、平和な植民星を破壊の危機に陥れていました。\n",
      "---\n",
      "【順位 13 / スコア: 0.5944】\n",
      "遥か未来、人類が宇宙へと進出した時代。\n",
      "---\n",
      "【順位 14 / スコア: 0.5943】\n",
      "そこは無数のアステロイドが飛び交う危険な宙域でした。\n",
      "---\n",
      "【順位 15 / スコア: 0.5899】\n",
      "彼は生まれながらにして宇宙空間での活動に適応しており、驚異的な身体能力を持っていました。\n",
      "---\n",
      "【順位 16 / スコア: 0.5783】\n",
      "葡萄太郎の活躍は全星系に知れ渡り、\n",
      "彼は宇宙の平和を守る英雄として、末永くその名を語り継がれることになりました。\n",
      "---\n",
      "【順位 17 / スコア: 0.5628】\n",
      "その葡萄は、一粒一粒が家ほどもあり、美しい紫色に輝いていました。\n",
      "---\n",
      "【順位 18 / スコア: 0.5518】\n",
      "彼は奪われた宝物と資源を解放し、\n",
      "それらを元の持ち主である各植民星に返還しました。\n",
      "---\n",
      "【順位 19 / スコア: 0.5488】\n",
      "「僕が行って、ジャークマターを懲らしめてきます」。\n",
      "---\n",
      "【順位 20 / スコア: 0.5467】\n",
      "「まあ、なんて珍しい葡萄でしょう」。\n",
      "---\n",
      "【順位 21 / スコア: 0.5402】\n",
      "夫はデブリ回収業者として宇宙を飛び回り、妻は小惑星の自宅で水耕栽培をしていました。\n",
      "---\n",
      "【順位 22 / スコア: 0.5365】\n",
      "妻は驚きながらも、マニピュレーターアームを巧みに操り、\n",
      "その巨大な葡萄の一粒を慎重に回収し、居住ブロックへと運び込みました。\n",
      "---\n",
      "【順位 23 / スコア: 0.5357】\n",
      "あまりの大きさと美しさに夫も目を見張りました。\n",
      "---\n",
      "【順位 24 / スコア: 0.5272】\n",
      "次に立ち寄ったジャングル惑星では、驚異的な知能を持つ猿型サイボーグ「サル-Z」の助けを借り、\n",
      "最後に、廃墟となった宇宙ステーションで、\n",
      "超高速で飛行する鳥型ドローン「キジ-V」を修理して仲間に加えました。\n",
      "---\n",
      "【順位 25 / スコア: 0.5203】\n",
      "激しい弾幕をかいくぐり、敵の防衛網を突破した彼らは、\n",
      "ついに宇宙海賊の巨大な母船に乗り込みます。\n",
      "---\n",
      "【順位 26 / スコア: 0.5190】\n",
      "数年後、たくましい青年に成長した葡萄太郎は、\n",
      "近隣の星系を荒らし回る悪名高い宇宙海賊「ジャークマター」の噂を耳にします。\n",
      "---\n",
      "【順位 27 / スコア: 0.5165】\n",
      "「我々の邪魔をするとは、愚かな地球人め！」。\n",
      "---\n",
      "【順位 28 / スコア: 0.5106】\n",
      "ある日、妻がドッキングポートで宇宙船の洗浄をしていると、\n",
      "観測史上ないほど巨大な宇宙葡萄の房が、ゆっくりと自転しながら近づいてきました。\n",
      "---\n",
      "【順位 29 / スコア: 0.5089】\n",
      "食べれば不老不死になれるという…」。\n",
      "---\n",
      "【順位 30 / スコア: 0.4733】\n",
      "「これはきっと、伝説の『創世の葡萄』に違いない。\n",
      "---\n",
      "【順位 31 / スコア: 0.4661】\n",
      "二人が期待に胸を膨らませ、レーザーカッターでその葡萄の厚い皮に切れ込みを入れると、\n",
      "まばゆい光と共に、中から元気な男の子の赤ちゃんが現れたのです。\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# スコアとチャンクをペアにして、スコアの高い順に並べ替える\n",
    "scored_chunks = sorted(zip(chunks, similarities.flatten()), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"--- 関連度の高い順に並べ替えたチャンク ---\")\n",
    "for i, (chunk, score) in enumerate(scored_chunks):\n",
    "    print(f\"【順位 {i+1} / スコア: {score:.4f}】\")\n",
    "    print(chunk.strip())\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑「葡萄太郎、仲間、敵という言葉から連想される言葉」という部分を含むチャンクのスコアが最も高くなっていることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ステップC：生成（Generation）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAGの核心：プロンプトの「拡張」(Augmented)**\n",
    "\n",
    "いよいよ最終ステップです。ここで行うのは、検索で見つけ出した関連性の高いチャンク（＝コンテキスト）を、元の質問と組み合わせて、LLMへの**プロンプトを「拡張」する**ことです。\n",
    "\n",
    "これにより、LLMはゼロから答えを「思い出す」のではなく、与えられたコンテキストという「カンニングペーパー」を基に、より正確な回答を生成できるようになります。これが、RAGがハルシネーション（事実に基づかない情報の生成）を抑制できる理由です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAIのクライアントを初期化\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 「RAGあり」プロンプトの組み立て\\n\n",
    "\\n\n",
    "ステップBでスコアが高かった上位3件のチャンクを「コンテキスト」として、最終的なプロンプトを組み立ててみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AIに渡す最終プロンプト（RAGあり） ---\n",
      "\n",
      "以下の参考情報を使って、質問に答えてください。参考情報に答えがない場合は、「分かりません」と答えてください。\n",
      "\n",
      "--- \n",
      "【参考情報】\n",
      "\n",
      "旅の途中、葡萄太郎は3体のユニークな仲間と出会います。\n",
      "\n",
      "\n",
      "激しい戦闘の末、葡萄太郎は仲間たちとの連携プレイで首領を打ち破り、\n",
      "ジャークマターを降伏させました。\n",
      "\n",
      "\n",
      "葡萄太郎と3体の仲間たちは、宇宙艇でジャークマターの本拠地である暗黒星雲へと向かいました。\n",
      "--- \n",
      "【質問】\n",
      "葡萄太郎の仲間とが倒した相手は誰ですか？\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 上位3件のチャンクをコンテキストとして使用\\n\n",
    "top_n = 3\n",
    "context = \"\\n\\n\".join([chunk for chunk, score in scored_chunks[:top_n]])\n",
    "\n",
    "# プロンプトテンプレート\n",
    "prompt_template = f\"\"\"\n",
    "以下の参考情報を使って、質問に答えてください。参考情報に答えがない場合は、「分かりません」と答えてください。\n",
    "\n",
    "--- \n",
    "【参考情報】\n",
    "{context}\n",
    "--- \n",
    "【質問】\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "final_prompt = prompt_template.format(context=context, question=question)\n",
    "\n",
    "print(\"--- AIに渡す最終プロンプト（RAGあり） ---\")\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 「RAGあり」での回答生成 ---\n",
      "首領です。仲間と協力して首領を打ち破り、その後ジャークマターを降伏させました。\n"
     ]
    }
   ],
   "source": [
    "# 「RAGありプロンプト」で回答を生成\\n\n",
    "print(\"\\n--- 「RAGあり」での回答生成 ---\")\n",
    "response_rag = client.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "        {\"role\": \"user\", \"content\": final_prompt}\n",
    "    ]\n",
    ")\n",
    "print(response_rag.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 比較：RAGなしの場合\n",
    "\n",
    "比較のために、コンテキストを与えずに、ユーザーの質問だけをLLMに渡してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AIに渡すプロンプト（RAGなし） ---\n",
      "葡萄太郎の仲間とが倒した相手は誰ですか？\n",
      "\n",
      "--- 「RAGなし」での回答生成 ---\n",
      "おそらく「桃太郎」のことを指していると思います。もし別の作品のことなら教えてください。\n",
      "\n",
      "桃太郎と仲間（犬・猿・雉）が倒した相手は鬼（おに）です。鬼ヶ島の鬼を討伐します。\n"
     ]
    }
   ],
   "source": [
    "# 「RAGなしプロンプト」（質問のみ）\n",
    "prompt_no_rag = question\n",
    "\n",
    "print(\"--- AIに渡すプロンプト（RAGなし） ---\")\n",
    "print(prompt_no_rag)\n",
    "\n",
    "print(\"\\n--- 「RAGなし」での回答生成 ---\")\n",
    "response_no_rag = client.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "        {\"role\": \"user\", \"content\": prompt_no_rag}\n",
    "    ]\n",
    ")\n",
    "print(response_no_rag.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 考察：RAGあり/なしの回答を比較してみましょう\n",
    "\n",
    "2つの回答を比べてみると、以下のことが分かります。\n",
    "\n",
    "*   **RAGありの場合:** 与えられた「参考情報」に忠実に、葡萄太郎の内容について回答しています。\n",
    "*   **RAGなしの場合:** モデルが元々持っている知識から回答を生成しようとします。葡萄太郎はこのために作ったデタラメな物語であるため、正しく回答することはできません。\n",
    "\n",
    "このように、RAGは、**外部の信頼できる情報源を基に回答を生成する**ことで、LLMの回答の正確性と信頼性を向上させる強力な技術です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### おまけ\n",
    "\n",
    "PDFファイルをベクトル化し、supabaseにベクトルデータとして保管できるようにしてみましょう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
